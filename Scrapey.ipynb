{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Scrapey.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltpIob5yW9SH",
        "colab_type": "text"
      },
      "source": [
        "Scrape www.healthgrades.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNId9YXcrFvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "from time import sleep\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj304J9-q4yb",
        "colab_type": "code",
        "outputId": "d38ba0a2-93ce-48f1-90b0-9332a3862625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "#NOTE: This cell may not work in Google Colab, since it opens a new Chrome Window\n",
        "#Use headless browser to render doctor URL list\n",
        "from selenium import webdriver\n",
        "pathy='Path_to_chromedriver.exe' #Path to chromedriver.exe driver\n",
        "\n",
        "#Scrape doctor URL List\n",
        "pagelimit=525 #Number of webpages in directory \n",
        "\n",
        "#Internal Medicine Doctors in California\n",
        "for page in pages:\n",
        "    urlstart = \"https://www.healthgrades.com/usearch?what=Internal%20Medicine&entityCode=PS412&where=CA&pageNum=\"\n",
        "    urlend = \"&sort.provider=bestmatch&state=CA\"\n",
        "    url=urlstart+page+urlend\n",
        "    driver = webdriver.Chrome(pathy)\n",
        "    driver.get(url);\n",
        "    time.sleep(3)\n",
        "    doclist=[]\n",
        "    for a in driver.find_elements_by_xpath('.//a'):\n",
        "        b = a.get_attribute('href')\n",
        "        try: \n",
        "            if b.startswith(\"https://www.healthgrades.com/physician/\"):\n",
        "                doclist=np.append(doclist,b)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "    driver.quit()\n",
        "    np.savetxt(page+\".txt\",doclist, fmt='%s')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3f25a72aac60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpathy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C:\\\\Users\\\\louis\\\\Medical Image\\chromedriver.exe'\u001b[0m \u001b[0;31m#BrowserDriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#os.chdir('C:\\\\Users\\\\louis\\\\DocScrape')                  #Directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnMAZHHTYKYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Combine all pages into one text file\n",
        "pages=[]\n",
        "for i in range(1,pagelimit):\n",
        "    pages=np.append(pages,str(i))\n",
        "\n",
        "pagenames=[]\n",
        "for page in pages:\n",
        "    pagenames=np.append(pagenames,page+\".txt\")\n",
        "\n",
        "ofile=\"internal_CA.txt\"\n",
        "filenames = pagenames\n",
        "with open(ofile, 'w') as outfile:\n",
        "    for fname in filenames:\n",
        "        with open(fname) as infile:\n",
        "            outfile.write(infile.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5PVSkqgq4y0",
        "colab_type": "code",
        "outputId": "c71de584-ef5d-4289-b806-2de2f4f6346e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#Strip \"leave-review\" from doctor URLs\n",
        "def deleteLine():\n",
        "    fn = 'internal_CA.txt'\n",
        "    f = open(fn)\n",
        "    output = []\n",
        "    str=\"leave-review\"\n",
        "    for line in f:\n",
        "        if not 'leave-review' in line:\n",
        "            output.append(line)\n",
        "    f.close()\n",
        "    f = open(fn, 'w')\n",
        "    f.writelines(output)\n",
        "    f.close()\n",
        "deleteLine()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d856dd7c48c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdeleteLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-d856dd7c48c9>\u001b[0m in \u001b[0;36mdeleteLine\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeleteLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'internal_CA.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"leave-review\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'internal_CA.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLppyVugq4zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define text find function\n",
        "def find_all(a_str, sub):\n",
        "    start = 0\n",
        "    while True:\n",
        "        start = a_str.find(sub, start)\n",
        "        if start == -1: return\n",
        "        yield start\n",
        "        start += len(sub) # use start += 1 to find overlapping matches\n",
        "\n",
        "def getLinks(url):\n",
        "    html_page = requests.get(url).content\n",
        "    soup = BeautifulSoup(html_page)\n",
        "    links = []\n",
        "\n",
        "    for link in soup.findAll('a', attrs={'href': re.compile(\"^https://\")}):\n",
        "        links.append(link.get('href'))\n",
        "\n",
        "    return links"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6QMA6vCq4zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load URLs\n",
        "with open('internal_CA.txt', 'r') as f:\n",
        "    x = f.readlines()\n",
        "docnames = [line.rstrip() for line in x]    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EJ7Dflsq4zi",
        "colab_type": "code",
        "outputId": "d47fc76d-9074-46ca-b6c7-08f17da9f4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Scrape data from individual doctor pages\n",
        "startdoc=0 #To resume after interruption\n",
        "dics=[]\n",
        "maxreviews=20 #Maximum Patient reviews per doctor\n",
        "for docurl in tqdm(docnames[startdoc:]): \n",
        "    url = docurl\n",
        "    dic={}\n",
        "    comments1=url+\"/comments\"\n",
        "\n",
        "    r = requests.get(url).content\n",
        "    soup = BeautifulSoup(r)\n",
        "    alltext=soup.get_text()\n",
        "\n",
        "    r2 = requests.get(comments1).content\n",
        "    soup2 = BeautifulSoup(r2)\n",
        "    alltext2=soup2.get_text()\n",
        "\n",
        "    comcity=list(find_all(alltext,\"locationCity\"))\n",
        "    f1=alltext[comcity[0]+14:comcity[0]+200]\n",
        "    f2=f1.split(':')[0].split(',')[0].replace(u'\\u0022',\"\")\n",
        "    city=f2\n",
        "\n",
        "    com=list(find_all(alltext,\"responseCount\"))\n",
        "    findy=alltext[com[0]:com[0]+100]\n",
        "    findy2=findy.split(\"text\")[0].split(\":\")\n",
        "    responseCount=float(findy2[1].split(',')[0])\n",
        "    reviewCount=float(findy2[2].split(',')[0])\n",
        "    actualScore=float(findy2[3].split(',')[0])\n",
        "    roundedScore=float(findy2[4].split(',')[0])\n",
        "    com2=list(find_all(alltext,\"providerName\"))\n",
        "    findy3=alltext[com2[0]+15:com2[0]+100]\n",
        "    providerName=findy3.split(\"providerPossessiveName\")[0][:-3]\n",
        "    \n",
        "    try:\n",
        "        comage=list(find_all(alltext,\"Age\"))\n",
        "        age=alltext[int(comage[0]+4):int(comage[0])+6]\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    comgen=list(find_all(soup.get_text(),\"genderString\"))\n",
        "    gender=alltext[comgen[0]+15:comgen[0]+16]\n",
        "        \n",
        "    com3=list(find_all(alltext2,'Submitted on'))\n",
        "    com4=list(find_all(alltext2,'Author'))\n",
        "    \n",
        "    try:\n",
        "        comlang=list(find_all(alltext,\"languages\"))[1]\n",
        "        lang=alltext[comlang+12:comlang+50].split(\"],\")[0]\n",
        "        langs=lang.replace(u'\\u0022',\"\").split(\",\")\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    try:\n",
        "        charlimit=1000\n",
        "        allstars=[]\n",
        "        texts=[]\n",
        "        for patient in range(int(len(com4))):\n",
        "            dateSub=alltext2[com3[patient]+13:com3[patient]+29]\n",
        "            stars=alltext2[com4[patient]-1:com4[patient]]\n",
        "            allstars=np.append(allstars,stars)\n",
        "            texty=alltext2[com3[patient]+29:com3[patient]+charlimit].split(\"Author:\")[0][:-1]\n",
        "            texts=np.append(texts,texty)\n",
        "        ids=url.split(\"-\")[-1]\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    try:\n",
        "        dic={'Doctor':providerName,\"Age\":int(age),\"Gender\":gender,\"Responses\":int(responseCount),\n",
        "         \"Reviews\":int(reviewCount),\"Actual_Score\":np.around(actualScore,4),\"Rounded_Score\":roundedScore,\n",
        "         \"URL\":url,\"ID\":ids,\"City\":city}\n",
        "    except: \n",
        "        pass\n",
        "    \n",
        "    try:\n",
        "        dic[\"Lang1\"]=langs[0]\n",
        "    except: \n",
        "        pass\n",
        "    try:\n",
        "        dic[\"Lang2\"]=langs[1]\n",
        "    except: \n",
        "        pass\n",
        "    try:\n",
        "        dic[\"Lang3\"]=langs[2]\n",
        "    except: \n",
        "        pass\n",
        "    try:\n",
        "        dic[\"Lang4\"]=langs[3]\n",
        "    except: \n",
        "        pass\n",
        "    \n",
        "    assert len(texts)==len(allstars)\n",
        "    maxpatients=min(maxreviews,int(reviewCount))\n",
        "\n",
        "    try:  \n",
        "      for patient in range(maxpatients):\n",
        "          dic[\"Stars\"+str(patient).zfill(2)]=allstars[patient]\n",
        "          dic[\"Text\"+str(patient).zfill(2)]=texts[patient]\n",
        "    except: \n",
        "      pass\n",
        "    \n",
        "    dics.append(dic)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10352/10352 [1:38:10<00:00,  1.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y37TCEkq4zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Export to Excel File\n",
        "df = pd.DataFrame.from_dict(dics)\n",
        "dforder=df[['Actual_Score',\t'Age',\t'Doctor',\t'Gender',\t'ID',\t'Lang1', 'Lang2',\t'Lang3', 'Lang4', 'Responses',\t'Reviews',\t'Rounded_Score',\t'Stars00',\t'Stars01',\t'Stars02',\t'Stars03',\t'Stars04',\t'Stars05',\t'Stars06',\t'Stars07',\t'Stars08',\t'Stars09',\t'Stars10',\t'Stars11',\t'Stars12',\t'Stars13',\t'Stars14',\t'Stars15',\t'Stars16',\t'Stars17',\t'Stars18',\t'Stars19',\t'Text00',\t'Text01',\t'Text02',\t'Text03',\t'Text04',\t'Text05',\t'Text06',\t'Text07',\t'Text08',\t'Text09',\t'Text10',\t'Text11',\t'Text12',\t'Text13',\t'Text14',\t'Text15',\t'Text16',\t'Text17',\t'Text18',\t'Text19',\t'URL',\t'City']]\n",
        "dforder.to_excel(\"Internal_CA.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}